{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd8a001-01a7-4f8b-986e-046e5e33a94c",
   "metadata": {
    "id": "9dd8a001-01a7-4f8b-986e-046e5e33a94c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10524252-27f7-460e-9d09-2384fb4d328e",
   "metadata": {
    "id": "10524252-27f7-460e-9d09-2384fb4d328e"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import wordnet, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "yrohsMNxhXpO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yrohsMNxhXpO",
    "outputId": "fa3bc159-92db-4967-bee8-d59e4336765f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c51363e-6897-4cb4-bbb6-92121c88bc1a",
   "metadata": {
    "id": "8c51363e-6897-4cb4-bbb6-92121c88bc1a"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e04942-fc5b-4e98-b6b3-099a555a5e76",
   "metadata": {
    "id": "19e04942-fc5b-4e98-b6b3-099a555a5e76"
   },
   "outputs": [],
   "source": [
    "X = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d78fb0-111b-4680-aa91-7275ca0221b4",
   "metadata": {
    "id": "52d78fb0-111b-4680-aa91-7275ca0221b4"
   },
   "outputs": [],
   "source": [
    "with open('edgar_allan_poe.txt') as f:\n",
    "    line = ''\n",
    "    for l in f:\n",
    "        l = l.replace('\\n','')\n",
    "        if len(l) < 2:\n",
    "          X.append([line])\n",
    "          line = ''\n",
    "        else:\n",
    "          if line == '':\n",
    "            line = l\n",
    "          else:\n",
    "            line = line + ' ' + l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "xSFmLPVFjmvU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSFmLPVFjmvU",
    "outputId": "34e0b576-2d16-42d0-8614-49b435d5ff6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ece2d-3522-4927-a9c6-cc38ba3e6199",
   "metadata": {
    "id": "c89ece2d-3522-4927-a9c6-cc38ba3e6199"
   },
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf3c1fb9-ed5e-40da-b38b-539e07c52cb3",
   "metadata": {
    "id": "bf3c1fb9-ed5e-40da-b38b-539e07c52cb3"
   },
   "outputs": [],
   "source": [
    "class LanguageModel():\n",
    "  def __init__(self):\n",
    "    self.TF = {}\n",
    "    self.Pi = {}\n",
    "    self.A = {}\n",
    "    self.A3 = {}\n",
    "    self.n = 0\n",
    "\n",
    "  def text_preprocess(self, s):\n",
    "    s = s.lower()\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "    return s\n",
    "\n",
    "  def add_TF(self, word):\n",
    "    if word in self.TF.keys():\n",
    "      self.TF[word] += 1\n",
    "    else:\n",
    "      self.TF[word] = 1\n",
    "\n",
    "  def fit(self, docs):\n",
    "    for doc in docs:\n",
    "      doc = word_tokenize(self.text_preprocess(doc[0]))\n",
    "      order = 0\n",
    "      t_2 = ''\n",
    "      t_1 = ''\n",
    "      for word in doc:\n",
    "        if order == 0:\n",
    "          if word in self.Pi.keys():\n",
    "            self.Pi[word] += 1\n",
    "          else:\n",
    "            self.Pi[word] = 1\n",
    "          self.add_TF(word)\n",
    "          t_1 = word\n",
    "\n",
    "        elif order == 1:\n",
    "          if t_1 in self.A.keys():\n",
    "            if word in self.A[t_1].keys():\n",
    "              self.A[t_1][word] += 1\n",
    "            else:\n",
    "              self.A[t_1][word] = 1\n",
    "          else:\n",
    "            self.A[t_1] = {}\n",
    "            self.A[t_1][word] = 1\n",
    "\n",
    "          self.add_TF(word)\n",
    "          t_2 = t_1\n",
    "          t_1 = word\n",
    "\n",
    "        elif order > 1:\n",
    "          if t_2 in self.A3.keys():\n",
    "            if t_1 in self.A3[t_2].keys():\n",
    "              if word in self.A3[t_2][t_1].keys():\n",
    "                self.A3[t_2][t_1][word] += 1\n",
    "              else:\n",
    "                self.A3[t_2][t_1][word] = 1\n",
    "            else:\n",
    "              self.A3[t_2][t_1] = {}\n",
    "              self.A3[t_2][t_1][word] = 1\n",
    "          else:\n",
    "            self.A3[t_2] = {}\n",
    "            self.A3[t_2][t_1] = {}\n",
    "            self.A3[t_2][t_1][word] = 1\n",
    "\n",
    "          self.add_TF(word)\n",
    "          t_2 = t_1\n",
    "          t_1 = word\n",
    "        order += 1\n",
    "      self.n += 1\n",
    "\n",
    "  def generate(self, start='', token_limit=20):\n",
    "    buffer = []\n",
    "    if start != '':\n",
    "      buffer.append(start.lower())\n",
    "    for i in range(token_limit):\n",
    "      try:\n",
    "        if len(buffer) == 0:\n",
    "          keys = list(self.Pi.keys())\n",
    "          values = list(self.Pi.values())\n",
    "          probs = np.array(values)\n",
    "          probs = probs / self.n\n",
    "          idx = np.random.choice(len(keys), p=probs)\n",
    "          word = keys[idx]\n",
    "          buffer.append(word)\n",
    "        elif len(buffer) == 1:\n",
    "          t_1 = buffer[-1]\n",
    "          keys = list(self.A[t_1].keys())\n",
    "          values = list(self.A[t_1].values())\n",
    "          probs = np.array(values) / sum(values)\n",
    "          idx = np.random.choice(len(keys), p=probs)\n",
    "          word = keys[idx]\n",
    "          buffer.append(word)\n",
    "        elif len(buffer) > 1:\n",
    "          t_2 = buffer[-2]\n",
    "          t_1 = buffer[-1]\n",
    "          keys = list(self.A3[t_2][t_1].keys())\n",
    "          values = list(self.A3[t_2][t_1].values())\n",
    "          probs = np.array(values) / sum(values)\n",
    "          idx = np.random.choice(len(keys), p=probs)\n",
    "          word = keys[idx]\n",
    "          buffer.append(word)\n",
    "      except KeyError:\n",
    "        break\n",
    "\n",
    "    text = ''\n",
    "    for token in buffer:\n",
    "      if text == '':\n",
    "        text = token.capitalize()\n",
    "      else:\n",
    "        text = text + ' ' + token\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "SUQxV69SmuzI",
   "metadata": {
    "id": "SUQxV69SmuzI"
   },
   "outputs": [],
   "source": [
    "model = LanguageModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "QCoc_1nzmyjv",
   "metadata": {
    "id": "QCoc_1nzmyjv"
   },
   "outputs": [],
   "source": [
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aNA4_K9qp0qV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "aNA4_K9qp0qV",
    "outputId": "4259d430-8742-4eee-d008-a00f32e155eb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I saw but them they were the world thy gentle ways thy grace thy more than beauty shall be and given in beauty from his birth whose fervid flickering torch of life was lit from the silver tinkling throats of the bells ah the bells the heavy iron bells how horrible a monody there floats from their throats from their deeptoned throats from their throats from the sun did rivulets run and all thy melody of lipbegotten words'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(start='i', token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XJ5wTGYCpHTu",
   "metadata": {
    "id": "XJ5wTGYCpHTu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
